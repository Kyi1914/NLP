{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.25.2', '2.1.0', '3.7.2')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__, matplotlib.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
    "          \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]\n",
    "\n",
    "# note : embedding of banana should be the same as embedding of apple and fruit, ws = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'animal', 'dog'],\n",
       " ['cat', 'dog', 'animal']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. tokenization\n",
    "corpus = [sent.split(\" \") for sent in corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. numericalization\n",
    "# find the unique words\n",
    "flatten = lambda l:[item for sublist in l for item in sublist]\n",
    "\n",
    "# assign unique integer\n",
    "vocabs = list(set(flatten(corpus))) # all the words we have in the system ; <UNK>: for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'apple', 'animal', 'cat', 'fruit', 'banana']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create handy mapping betweem integer and word\n",
    "word2index = {v:idx for idx,v in enumerate(vocabs)} # a dictionary array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 0, 'apple': 1, 'animal': 2, 'cat': 3, 'fruit': 4, 'banana': 5}\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(word2index)\n",
    "print(word2index['dog'])\n",
    "print(word2index['apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <UNK>\n",
    "vocabs.append(\"<UNK>\")\n",
    "word2index['<UNK>'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0,\n",
       " 'apple': 1,\n",
       " 'animal': 2,\n",
       " 'cat': 3,\n",
       " 'fruit': 4,\n",
       " 'banana': 5,\n",
       " '<UNK>': 6}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index to word\n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dog',\n",
       " 1: 'apple',\n",
       " 2: 'animal',\n",
       " 3: 'cat',\n",
       " 4: 'fruit',\n",
       " 5: 'banana',\n",
       " 6: '<UNK>'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs of center word and outside word\n",
    "\n",
    "def random_batch(batch_size, corpus):\n",
    "    \n",
    "    skipgrams = []\n",
    "\n",
    "    # loop each corpus\n",
    "    for doc in corpus:\n",
    "        \n",
    "        # look from the 2nd word until second last word\n",
    "        for i in range (1, len(doc)-1):\n",
    "            \n",
    "            # assign center word\n",
    "            center = word2index[doc[i]]\n",
    "                \n",
    "            # assign outside word = 2 words (if ws = 2, we must assign 2 outside word for each center word )\n",
    "            outside = (word2index[doc[i-1]], word2index[doc[i+1]])\n",
    "            \n",
    "            # for each of these two outside words, we gonna append to a list\n",
    "            for each_out in outside:\n",
    "                \n",
    "                #center, outside1; cener, outside2;\n",
    "                skipgrams.append([center,each_out])\n",
    "                \n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace = False)\n",
    "    \n",
    "    inputs, labels = [], []\n",
    "    for index in random_index:\n",
    "        inputs.append([skipgrams[index][0]]) # center word\n",
    "        labels.append([skipgrams[index][1]]) # outside word\n",
    "    \n",
    "    return np.array(inputs), np.array(labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_batch (2, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # batch_size, 1 >> input to nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [2]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape # batch_size,1 >> input to nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{\\substack{-m \\leq j \\leq m \\\\ j \\neq 0}} \\log P(w_{t+j} | w_t; \\theta)$$\n",
    "\n",
    "where $P(w_{t+j} | w_t; \\theta) = $\n",
    "\n",
    "$$P(o|c) = \\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$\n",
    "\n",
    "where $o$ is the outside words and $c$ is the center word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(7, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4666,  1.4091]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.LongTensor([3])\n",
    "embedding(a)\n",
    "\n",
    "# if we enter 3, embedding can return a vector for 3\n",
    "    # Note: as we mention (7,2) \n",
    "    # vector dim: 2\n",
    "    # range     : (0-7) // each number represent for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5075,  1.8527]],\n",
       "\n",
       "        [[-1.4666,  1.4091]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.LongTensor(x)\n",
    "embedding(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(x_tensor).shape # batch_size, 1, embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        center_embedding     = self.embedding_center(center)     # (batch_size, 1, embedding_size)\n",
    "        outside_embedding    = self.embedding_center(outside)    # (batch_size, 1, embedding_size)\n",
    "        all_vocabs_embedding = self.embedding_center(all_vocabs) # (batch_size, vocab_size, embedding_size)\n",
    "        \n",
    "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1,2)).squeeze(2))\n",
    "        # (batch_size, 1,1) = (batch_size , 1, emb_size) @ (batch_size, emb_size, 1)\n",
    "        # squeeze (batch_size, 1, 1) to (batch_size,1); use squeeze(dimension to squeeze)\n",
    "        # (batch_size,1) = (batch_size , 1, emb_size) @ (batch_size, emb_size, 1)\n",
    "        \n",
    "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1,2)).squeeze(2)\n",
    "        # (batch_size, voc_size, 1)= (batch_size , voc_size, emb_size) @ (batch_size, emb_size, 1)\n",
    "        # (batch_size, voc_size)   = (batch_size , voc_size, emb_size) @ (batch_size, emb_size, 1)\n",
    "        \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) # (batch_size, 1)\n",
    "        # 1 means sum across vocab_size >> (batch_size, voc_size) = (0,1)\n",
    "        \n",
    "        loss = -torch.mean(torch.log(top_term / lower_term_sum)) # scaler\n",
    "        # loss needs to be only one number, we have (batch_size,1), so we take average in order to get only one number.\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare all vocabs\n",
    "\n",
    "batch_size = 2\n",
    "voc_size = len(vocabs)\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index('<UNK>'), seq))\n",
    "    # map (function, list that you want to apply to that function)\n",
    "    return torch.LongTensor(idxs)\n",
    "    # nn accept only Tensor input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'apple', 'animal', 'cat', 'fruit', 'banana', '<UNK>']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### testing cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [2]]),\n",
       " array([[2],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(7, 2)\n",
       "  (embedding_outside): Embedding(7, 2)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "model = Skipgram(voc_size, 2) # (voc_size, batch_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.LongTensor(x)\n",
    "label_tensor = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model (input_tensor, label_tensor, all_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3672, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "emb_size   = 2\n",
    "model      = Skipgram(voc_size, emb_size)\n",
    "optimizer  = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1000 | Loss: 1.075362\n",
      "Epoch:   2000 | Loss: 1.165164\n",
      "Epoch:   3000 | Loss: 1.099131\n",
      "Epoch:   4000 | Loss: 1.095224\n",
      "Epoch:   5000 | Loss: 1.075178\n",
      "Epoch:   6000 | Loss: 1.080026\n",
      "Epoch:   7000 | Loss: 1.123490\n",
      "Epoch:   8000 | Loss: 1.089580\n",
      "Epoch:   9000 | Loss: 1.122916\n",
      "Epoch:  10000 | Loss: 1.105575\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # get batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
    "    input_tensor = torch.LongTensor(input_batch)\n",
    "    label_tensor = torch.LongTensor(label_batch)\n",
    "    \n",
    "    # predict\n",
    "    loss = model(input_tensor, label_tensor, all_vocabs)\n",
    "    \n",
    "    # backpropagate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print the loss\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch+1:6.0f} | Loss: {loss:2.6f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is fruit really near to banana?\n",
    "Is fruit really far from cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'apple', 'animal', 'cat', 'fruit', 'banana', '<UNK>']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5])\n",
      "tensor([[1.3086, 1.3515]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[0.7823, 0.4675]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[1.0454, 0.9095]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "print(banana)\n",
    "\n",
    "banana_embed_c = model.embedding_center(banana)\n",
    "banana_embed_o = model.embedding_outside(banana)\n",
    "\n",
    "print(banana_embed_c), print(banana_embed_o)\n",
    "\n",
    "banana_embed = (banana_embed_o + banana_embed_c) / 2\n",
    "print(banana_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to plot the embedding # get the embedding\n",
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index[\"<UNK>\"]\n",
    "    \n",
    "    word = torch.LongTensor([word2index[word]])\n",
    "    embed_c = model.embedding_center(word)\n",
    "    embed_o = model.embedding_outside(word)\n",
    "    embed   = (embed_c + embed_o) / 2\n",
    "    \n",
    "    return list(embed[0][0].item(), embed[0][1].item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
