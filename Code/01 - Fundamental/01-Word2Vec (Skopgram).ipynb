{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.25.2', '2.1.0', '3.7.2')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__, matplotlib.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
    "          \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]\n",
    "\n",
    "# note : embedding of banana should be the same as embedding of apple and fruit, ws = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'animal', 'dog'],\n",
       " ['cat', 'dog', 'animal']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. tokenization\n",
    "corpus = [sent.split(\" \") for sent in corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. numericalization\n",
    "# find the unique words\n",
    "flatten = lambda l:[item for sublist in l for item in sublist]\n",
    "\n",
    "# assign unique integer\n",
    "vocabs = list(set(flatten(corpus))) # all the words we have in the system ; <UNK>: for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'apple', 'animal', 'cat', 'fruit', 'banana']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create handy mapping betweem integer and word\n",
    "word2index = {v:idx for idx,v in enumerate(vocabs)} # a dictionary array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 0, 'apple': 1, 'animal': 2, 'cat': 3, 'fruit': 4, 'banana': 5}\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(word2index)\n",
    "print(word2index['dog'])\n",
    "print(word2index['apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <UNK>\n",
    "vocabs.append(\"<UNK>\")\n",
    "word2index['<UNK>'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0,\n",
       " 'apple': 1,\n",
       " 'animal': 2,\n",
       " 'cat': 3,\n",
       " 'fruit': 4,\n",
       " 'banana': 5,\n",
       " '<UNK>': 6}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index to word\n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dog',\n",
       " 1: 'apple',\n",
       " 2: 'animal',\n",
       " 3: 'cat',\n",
       " 4: 'fruit',\n",
       " 5: 'banana',\n",
       " 6: '<UNK>'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs of center word and outside word\n",
    "\n",
    "def random_batch(batch_size, corpus):\n",
    "    \n",
    "    skipgrams = []\n",
    "\n",
    "    # loop each corpus\n",
    "    for doc in corpus:\n",
    "        \n",
    "        # look from the 2nd word until second last word\n",
    "        for i in range (1, len(doc)-1):\n",
    "            \n",
    "            # assign center word\n",
    "            center = word2index[doc[i]]\n",
    "                \n",
    "            # assign outside word = 2 words (if ws = 2, we must assign 2 outside word for each center word )\n",
    "            outside = (word2index[doc[i-1]], word2index[doc[i+1]])\n",
    "            \n",
    "            # for each of these two outside words, we gonna append to a list\n",
    "            for each_out in outside:\n",
    "                \n",
    "                #center, outside1; cener, outside2;\n",
    "                skipgrams.append([center,each_out])\n",
    "                \n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace = False)\n",
    "    \n",
    "    inputs, labels = [], []\n",
    "    for index in random_index:\n",
    "        inputs.append([skipgrams[index][0]]) # center word\n",
    "        labels.append([skipgrams[index][1]]) # outside word\n",
    "    \n",
    "    return np.array(inputs), np.array(labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_batch (2, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # batch_size, 1 >> input to nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [2]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape # batch_size,1 >> input to nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{\\substack{-m \\leq j \\leq m \\\\ j \\neq 0}} \\log P(w_{t+j} | w_t; \\theta)$$\n",
    "\n",
    "where $P(w_{t+j} | w_t; \\theta) = $\n",
    "\n",
    "$$P(o|c) = \\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$\n",
    "\n",
    "where $o$ is the outside words and $c$ is the center word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(7, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4666,  1.4091]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.LongTensor([3])\n",
    "embedding(a)\n",
    "\n",
    "# if we enter 3, embedding can return a vector for 3\n",
    "    # Note: as we mention (7,2) \n",
    "    # vector dim: 2\n",
    "    # range     : (0-7) // each number represent for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5075,  1.8527]],\n",
       "\n",
       "        [[-1.4666,  1.4091]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.LongTensor(x)\n",
    "embedding(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(x_tensor).shape # batch_size, 1, embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        center_embedding     = self.embedding_center(center)     # (batch_size, 1, embedding_size)\n",
    "        outside_embedding    = self.embedding_center(outside)    # (batch_size, 1, embedding_size)\n",
    "        all_vocabs_embedding = self.embedding_center(all_vocabs) # (batch_size, vocab_size, embedding_size)\n",
    "        \n",
    "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1,2)).squeeze(2))\n",
    "        # (batch_size, 1,1) = (batch_size , 1, emb_size) @ (batch_size, emb_size, 1)\n",
    "        # squeeze (batch_size, 1, 1) to (batch_size,1); use squeeze(dimension to squeeze)\n",
    "        # (batch_size,1) = (batch_size , 1, emb_size) @ (batch_size, emb_size, 1)\n",
    "        \n",
    "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1,2)).squeeze(2)\n",
    "        # (batch_size, voc_size, 1)= (batch_size , voc_size, emb_size) @ (batch_size, emb_size, 1)\n",
    "        # (batch_size, voc_size)   = (batch_size , voc_size, emb_size) @ (batch_size, emb_size, 1)\n",
    "        \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) # (batch_size, 1)\n",
    "        # 1 means sum across vocab_size >> (batch_size, voc_size) = (0,1)\n",
    "        \n",
    "        loss = -torch.mean(torch.log(top_term / lower_term_sum)) # scaler\n",
    "        # loss needs to be only one number, we have (batch_size,1), so we take average in order to get only one number.\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare all vocabs\n",
    "\n",
    "batch_size = 2\n",
    "voc_size = len(vocabs)\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index('<UNK>'), seq))\n",
    "    # map (function, list that you want to apply to that function)\n",
    "    return torch.LongTensor(idxs)\n",
    "    # nn accept only Tensor input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'apple', 'animal', 'cat', 'fruit', 'banana', '<UNK>']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### testing cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [2]]),\n",
       " array([[2],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(7, 2)\n",
       "  (embedding_outside): Embedding(7, 2)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "model = Skipgram(voc_size, 2) # (voc_size, batch_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.LongTensor(x)\n",
    "label_tensor = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model (input_tensor, label_tensor, all_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3672, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "emb_size   = 2\n",
    "model      = Skipgram(voc_size, emb_size)\n",
    "optimizer  = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1000 | Loss: 1.075362\n",
      "Epoch:   2000 | Loss: 1.165164\n",
      "Epoch:   3000 | Loss: 1.099131\n",
      "Epoch:   4000 | Loss: 1.095224\n",
      "Epoch:   5000 | Loss: 1.075178\n",
      "Epoch:   6000 | Loss: 1.080026\n",
      "Epoch:   7000 | Loss: 1.123490\n",
      "Epoch:   8000 | Loss: 1.089580\n",
      "Epoch:   9000 | Loss: 1.122916\n",
      "Epoch:  10000 | Loss: 1.105575\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # get batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
    "    input_tensor = torch.LongTensor(input_batch)\n",
    "    label_tensor = torch.LongTensor(label_batch)\n",
    "    \n",
    "    # predict\n",
    "    loss = model(input_tensor, label_tensor, all_vocabs)\n",
    "    \n",
    "    # backpropagate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print the loss\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch+1:6.0f} | Loss: {loss:2.6f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is fruit really near to banana?\n",
    "Is fruit really far from cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'apple', 'animal', 'cat', 'fruit', 'banana', '<UNK>']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5])\n",
      "tensor([[1.3086, 1.3515]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[0.7823, 0.4675]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[1.0454, 0.9095]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "print(banana)\n",
    "\n",
    "banana_embed_c = model.embedding_center(banana)\n",
    "banana_embed_o = model.embedding_outside(banana)\n",
    "\n",
    "print(banana_embed_c), print(banana_embed_o)\n",
    "\n",
    "banana_embed = (banana_embed_o + banana_embed_c) / 2\n",
    "print(banana_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to plot the embedding # get the embedding\n",
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index[\"<UNK>\"]\n",
    "    \n",
    "    word = torch.LongTensor([word2index[word]])\n",
    "    embed_c = model.embedding_center(word)\n",
    "    embed_o = model.embedding_outside(word)\n",
    "    embed   = (embed_c + embed_o) / 2\n",
    "    \n",
    "    return embed[0][0].item(), embed[0][1].item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6133660674095154, -0.14350289106369019)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('fruit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.34483003616333, -1.5633351802825928)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs):\n",
    "    x,y = get_embed(word)\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(word, xy = (x,y), xytext = (5,2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0454379320144653, 0.9094761610031128)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = get_embed('banana')\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6133660674095154, -0.14350289106369019)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = get_embed('fruit')\n",
    "fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510723694622996"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(banana) @ np.array(fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = get_embed('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.827752410042052"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(banana) @ np.array(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk = get_embed('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.884072177894012"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(banana) @ np.array(unk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
