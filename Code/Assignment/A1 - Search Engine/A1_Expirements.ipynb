{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirements for Task 2\n",
    "\n",
    "According to Task 2, I will conduct the follwings expirements:\n",
    "- (1) Compare Skip-gram, Skip-gram negative sampling, GloVe models on training loss, training time. \n",
    "- (2) Use Word analogies dataset to calucalte between syntactic and semantic accuracy, similar to the\n",
    "methods in the Word2Vec and GloVe paper. \n",
    "- (3) Use the similarity dataset to find the correlation between your modelsâ€™ dot product and the provided similarity metrics. (from scipy.stats import spearmanr) Assess if your embeddings correlate with human judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 3 models from main.py\n",
    "from main import Skipgram, SkipgramNeg, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing training data\n",
    "Data = pickle.load(open('./model/Data.pkl', 'rb'))\n",
    "corpus = Data['corpus']\n",
    "vocab = Data['vocab']\n",
    "word2index = Data['word2index']\n",
    "voc_size = Data['voc_size']\n",
    "embed_size = Data['embedding_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(4167, 2)\n",
       "  (embedding_outside): Embedding(4167, 2)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create object of the Skipgram model and load parameters\n",
    "Skipgram = Skipgram(voc_size, embed_size)\n",
    "Skipgram.load_state_dict(torch.load('model/A1-Skipgram.pt'))\n",
    "Skipgram.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object of the SkipgramNeg model and load parameters\n",
    "SkipgramNeg = SkipgramNeg(voc_size, embed_size)\n",
    "SkipgramNeg.load_state_dict(torch.load('model/A1-SkipgramNeg.pt'))\n",
    "SkipgramNeg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model and load saved parameters\n",
    "# glove = Glove(voc_size, embed_size)\n",
    "# glove.load_state_dict(torch.load('app/models/GloVe-v1.pt'))\n",
    "# glove.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to put this file in some python/gensim directory; just run it and it will inform where to put\n",
    "glove_file = ('./glove.6B/glove.6B.100d.txt')\n",
    "model = KeyedVectors.load_word2vec_format(glove_file, binary = False, no_header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for semantic and syntactic analysis \n",
    "that calculates similarities using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_similarity(word_vectors, result_vector):\n",
    "    # Calculate cosine similarities\n",
    "    similarities = F.cosine_similarity(result_vector, word_vectors)\n",
    "\n",
    "    # Find the index of the word with the highest similarity\n",
    "    closest_word_index = torch.argmax(similarities).item()\n",
    "\n",
    "    return closest_word_index\n",
    "\n",
    "def similarities(lines, model, vocab):\n",
    "    # Get word vectors for all words in the vocabulary\n",
    "    all_word_vectors = torch.stack([model.get_embed(word.lower()) for word in vocab])\n",
    "\n",
    "    correct = 0\n",
    "    # Perform vector manipulation for each set of four words\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "\n",
    "        # Assuming there are four words in each line\n",
    "        vectors = [model.get_embed(word.lower()) if word in vocab else model.get_embed('<UNK>') for word in words]\n",
    "\n",
    "        # Perform vector manipulation (e.g., subtraction, addition)\n",
    "        result_vector = vectors[1][0] - vectors[0][0] + vectors[2][0]\n",
    "\n",
    "        # Add a batch dimension to result_vector\n",
    "        result_vector = result_vector.unsqueeze(0)\n",
    "\n",
    "        # Find the closest word index using cosine similarity\n",
    "        closest_word_index = calculate_similarity(all_word_vectors, result_vector)\n",
    "\n",
    "        # Get the closest word from your vocabulary\n",
    "        closest_word = vocab[closest_word_index]\n",
    "\n",
    "        if closest_word == words[3]:\n",
    "            correct += 1\n",
    "\n",
    "        # Optionally, you can print the result for each line\n",
    "        # print(f\"The word with the closest cosine similarity to the result of {line} is: {closest_word}\")\n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "    print(f'Accuracy : {(correct / len(lines)) * 100: .2f}%')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) syntactic and semantic accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
