{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "# Process a text to create a Doc object\n",
    "doc = nlp(\"iPhone X is release on coming september third week!\")\n",
    "# doc.ents = [Span(doc, 0, 2, label=\"GADGET\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a span of tokens in the document\n",
    "span_of_tokens = doc[2:6]  # Represents tokens from index 2 to 5 (exclusive)\n",
    "span_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with the Span\n",
    "print(\"Text of the span:\", span_of_tokens.text)\n",
    "print(\"Tokens in the span:\", [token.text for token in span_of_tokens])\n",
    "print(\"Start index of the span:\", span_of_tokens.start)\n",
    "print(\"End index of the span:\", span_of_tokens.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Span\n",
    "new_span = Span(doc, start=0, end=2, label=\"CUSTOM_LABEL\")\n",
    "print(\"New span text:\", new_span.text)\n",
    "print(\"New span label:\", new_span.label_)\n",
    "print(type(new_span))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy.blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Create a blank English spaCy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process a text with the blank model\n",
    "doc = nlp(\"This is a blank spaCy model.\")\n",
    "\n",
    "# Access tokens in the document\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matcher Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Matcher is a powerful tool in spaCy for matching patterns in a text based on token attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a Matcher object using the vocabulary of the spaCy model\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define a pattern for matching the word \"example\"\n",
    "pattern = [{\"LOWER\": \"example\"}]\n",
    "\n",
    "# Add the pattern to the Matcher with a unique name (e.g., \"ExamplePattern\")\n",
    "matcher.add(\"ExamplePattern\", [pattern])\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"This is an example sentence. Another example is shown here.\")\n",
    "\n",
    "# Use the Matcher to find matches in the processed document\n",
    "matches = matcher(doc)\n",
    "print(f\"the patten matched: {matches}\")\n",
    "\n",
    "# Print the matches\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(f\"Match found: '{matched_span.text}' (start: {start}, end: {end})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: How to preorder the iPhone X\n",
      "spans: [iPhone X]\n",
      "doc.ents : (iPhone X,)\n",
      "doc: iPhone X is coming\n",
      "spans: [iPhone X]\n",
      "doc.ents : (iPhone X,)\n",
      "doc: Should I pay $1,000 for the iPhone X?\n",
      "spans: [iPhone X]\n",
      "doc.ents : (iPhone X,)\n",
      "doc: The iPhone 8 reviews are here\n",
      "spans: [iPhone 8]\n",
      "doc.ents : (iPhone 8,)\n",
      "doc: iPhone 11 vs iPhone 8: What's the difference?\n",
      "spans: [iPhone 11, iPhone 8]\n",
      "doc.ents : (iPhone 11, iPhone 8)\n",
      "doc: I need a new phone! Any tips?\n",
      "spans: []\n",
      "doc.ents : ()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "with open(\"data/iphone.json\", encoding=\"utf8\") as f:\n",
    "    text = json.loads(f.read())\n",
    "    # print(text)\n",
    "\n",
    "# Create a blank English spaCy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a Matcher object using the vocabulary of the spaCy model\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches \"iphone\" and a digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add patterns to the matcher and create docs with matched entities\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(text):\n",
    "    print(f\"doc: {doc}\")\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    print(f\"spans: {spans}\")\n",
    "    doc.ents = spans\n",
    "    print(f\"doc.ents : {doc.ents}\")\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[How to preorder the iPhone X,\n",
       " iPhone X is coming,\n",
       " Should I pay $1,000 for the iPhone X?,\n",
       " The iPhone 8 reviews are here,\n",
       " iPhone 11 vs iPhone 8: What's the difference?,\n",
       " I need a new phone! Any tips?]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Your Matcher definition (replace this with your actual pattern)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"example\"}]\n",
    "matcher.add(\"ExamplePattern\", [pattern])\n",
    "\n",
    "# List of texts to process\n",
    "# texts = [\"This is an example sentence.\", \"Another example is shown here.\"]\n",
    "with open(\"data/iphone.json\", encoding=\"utf8\") as f:\n",
    "    texts = json.loads(f.read())\n",
    "\n",
    "docs = []\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Create a list to store the entities\n",
    "    entities = []\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        # Create Span objects using the found matches\n",
    "        span = Span(doc, start, end, label=str(match_id))\n",
    "        entities.append(span)\n",
    "\n",
    "    # Assign the entities to the document's ents attribute\n",
    "    doc.ents = entities\n",
    "\n",
    "    # Append the modified document to the list\n",
    "    docs.append(doc)\n",
    "\n",
    "# Now, docs contains the processed documents with assigned entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy DocBin\n",
    "\n",
    "using spaCy's DocBin to convert a list of processed documents into a binary format suitable for training spaCy models. This binary format is useful for more efficient loading during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[How to preorder the iPhone X, iPhone X is coming, Should I pay $1,000 for the iPhone X?]\n",
      "[The iPhone 8 reviews are here, iPhone 11 vs iPhone 8: What's the difference?, I need a new phone! Any tips?]\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "# Assuming 'docs' is your list of processed documents\n",
    "\n",
    "# get the first half of the docs list and added to the train\n",
    "train_docs = docs[:len(docs) // 2]\n",
    "print(train_docs)\n",
    "# get the rest the docs list and added to the dev\n",
    "dev_docs = docs[len(docs) // 2:]\n",
    "print(dev_docs)\n",
    "\n",
    "# Create DocBin instances with an explicitly specified vocab\n",
    "train_doc_bin = DocBin(docs=train_docs)\n",
    "train_doc_bin.to_disk(\"docs/train.spacy\")\n",
    "\n",
    "dev_doc_bin = DocBin(docs=dev_docs)\n",
    "dev_doc_bin.to_disk(\"docs/dev.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'ABC Inc', 'email': 'john.doe@email.com', 'phone_number': None, 'skills': ['python', 'java']}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def parse_resume(text):\n",
    "    doc = nlp(text)\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Define patterns for common entities in a resume\n",
    "    name_pattern = [{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}]\n",
    "    email_pattern = [{\"LIKE_EMAIL\": True}]\n",
    "    phone_number_pattern = [{\"TEXT\": {\"REGEX\": r'\\d{3}-\\d{3}-\\d{4}'}}]\n",
    "    skills_pattern = [{\"LOWER\": {\"IN\": [\"python\", \"java\", \"machine learning\", \"data analysis\"]}}]\n",
    "\n",
    "    matcher.add(\"NAME\", [name_pattern])\n",
    "    matcher.add(\"EMAIL\", [email_pattern])\n",
    "    matcher.add(\"PHONE_NUMBER\", [phone_number_pattern])\n",
    "    matcher.add(\"SKILLS\", [skills_pattern])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    parsed_data = {\n",
    "        \"name\": None,\n",
    "        \"email\": None,\n",
    "        \"phone_number\": None,\n",
    "        \"skills\": []\n",
    "    }\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        match_id_str = nlp.vocab.strings[match_id]\n",
    "        if match_id_str == \"NAME\":\n",
    "            parsed_data[\"name\"] = doc[start:end].text\n",
    "        elif match_id_str == \"EMAIL\":\n",
    "            parsed_data[\"email\"] = doc[start:end].text\n",
    "        elif match_id_str == \"PHONE_NUMBER\":\n",
    "            parsed_data[\"phone_number\"] = doc[start:end].text\n",
    "        elif match_id_str == \"SKILLS\":\n",
    "            parsed_data[\"skills\"].append(doc[start:end].text.lower())\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "# Example usage\n",
    "resume_text = \"\"\"\n",
    "John Doe\n",
    "Email: john.doe@email.com\n",
    "Phone: 123-456-7890\n",
    "\n",
    "Skills: Python, Java, Machine Learning\n",
    "\n",
    "Work Experience:\n",
    "- Software Engineer at XYZ Corp\n",
    "- Data Scientist at ABC Inc\n",
    "\"\"\"\n",
    "\n",
    "parsed_data = parse_resume(resume_text)\n",
    "print(parsed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.entityruler.EntityRuler object at 0x176ac8bd0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m ruler\u001b[38;5;241m.\u001b[39madd_patterns(patterns)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Add the EntityRuler to the spaCy pipeline\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Process text\u001b[39;00m\n\u001b[1;32m     35\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI have experience in Python and Java, contact me at john.doe@email.com, and I worked at ABC Inc.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/language.py:807\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    805\u001b[0m     bad_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(factory_name)\n\u001b[1;32m    806\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE966\u001b[38;5;241m.\u001b[39mformat(component\u001b[38;5;241m=\u001b[39mbad_val, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    808\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n",
      "\u001b[0;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.entityruler.EntityRuler object at 0x176ac8bd0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Check if \"entity_ruler\" is in the pipeline and remove it if necessary\n",
    "if \"entity_ruler\" in nlp.pipe_names:\n",
    "    nlp.remove_pipe(\"entity_ruler\")\n",
    "\n",
    "# Initialize the EntityRuler\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Define patterns for skills, contact info, and experience\n",
    "patterns = [\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"python\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"java\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}]},\n",
    "    \n",
    "    {\"label\": \"CONTACT_INFO\", \"pattern\": [{\"LIKE_EMAIL\": True}]},\n",
    "    {\"label\": \"CONTACT_INFO\", \"pattern\": [{\"SHAPE\": \"ddd-ddd-dddd\"}]},  # Assuming a phone number pattern\n",
    "    \n",
    "    {\"label\": \"EXPERIENCE\", \"pattern\": [{\"POS\": \"PROPN\", \"IS_TITLE\": True}, {\"POS\": \"PROPN\", \"IS_TITLE\": True, \"OP\": \"?\"}, {\"LOWER\": {\"IN\": [\"at\", \"in\"]}, \"OP\": \"?\"}, {\"POS\": {\"IN\": [\"PROPN\", \"NUM\"]}}]}\n",
    "]\n",
    "\n",
    "# Add patterns to the ruler\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# Add the EntityRuler to the spaCy pipeline\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "# Process text\n",
    "doc = nlp(\"I have experience in Python and Java, contact me at john.doe@email.com, and I worked at ABC Inc.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract contact number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  contact number\n",
    "import re\n",
    "\n",
    "def extract_contact_number_from_resume(text):\n",
    "    contact_number = None\n",
    "\n",
    "    # Use regex pattern to find a potential contact number\n",
    "    pattern = r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        contact_number = match.group()\n",
    "\n",
    "    return contact_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95 9955649044'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I am Kyi Thin Nu +95 9955649044\"\n",
    "extract_contact_number_from_resume(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern Components\n",
    "Here’s a breakdown of the pattern components:\n",
    "\n",
    "- \\b: Matches a word boundary to ensure the number is not part of a larger word. \n",
    "- (?:\\+?\\d{1,3}[-.\\s]?)?: Matches an optional country code (e.g., +1 or +91) followed by an optional separator (-, ., or space). \n",
    "- \\(?: Matches an optional opening parenthesis for the area code. \n",
    "- \\d{3}: Matches exactly three digits for the area code. \n",
    "- \\)?: Matches an optional closing parenthesis for the area code. \n",
    "- [-.\\s]?: Matches an optional separator between the area code and the next part of the number. \n",
    "- \\d{3}: Matches exactly three digits for the next part of the number. \n",
    "- [-.\\s]?: Matches an optional separator between the next part of the number and the final part.\n",
    "- \\d{4}: Matches exactly four digits for the final part of the number.  \n",
    "- \\b: Matches a word boundary to ensure the number is not part of a larger word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_email_from_resume(text):\n",
    "    email = None\n",
    "\n",
    "    # Use regex pattern to find a potential email address\n",
    "    pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        email = match.group()\n",
    "\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kyi@ait.asia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"please reach me kyi@ait.asia\"\n",
    "extract_email_from_resume(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regex pattern used in this code is r”\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b”. Let’s break down the pattern:\n",
    "\n",
    "\\b: Represents a word boundary to ensure that the email address is not part of a larger word.\n",
    "[A-Za-z0-9._%+-]+: Matches one or more occurrences of alphabetic characters (both uppercase and lowercase), digits, periods, underscores, percent signs, or hyphens. This part represents the local part of the email address before the “@” symbol.\n",
    "@: Matches the “@” symbol.\n",
    "[A-Za-z0-9.-]+: Matches one or more occurrences of alphabetic characters (both uppercase and lowercase), digits, periods, or hyphens. This part represents the domain name (e.g., gmail, yahoo) of the email address.\n",
    "\\.: Matches a period (dot) character.\n",
    "[A-Za-z]{2,}: Matches two or more occurrences of alphabetic characters (both uppercase and lowercase). This part represents the top-level domain (e.g., com, edu) of the email address.\n",
    "\\b: Represents another word boundary to ensure the email address is not part of a larger word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_education_from_resume(text):\n",
    "    education = []\n",
    "\n",
    "    # List of education keywords to match against\n",
    "    education_keywords = ['Bsc', 'B. Pharmacy', 'B Pharmacy', 'Msc', 'M. Pharmacy', 'Ph.D', 'Bachelor', 'Master']\n",
    "\n",
    "    for keyword in education_keywords:\n",
    "        pattern = r\"(?i)\\b{}\\b\".format(re.escape(keyword))\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            education.append(match.group())\n",
    "\n",
    "    return education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Define name patterns\n",
    "    patterns = [\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # First name and Last name\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}],  # First name, Middle name, and Last name\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}]  # First name, Middle name, Middle name, and Last name\n",
    "        # Add more patterns as needed\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        matcher.add('NAME', patterns=[pattern])\n",
    "\n",
    "    doc = nlp(resume_text)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
