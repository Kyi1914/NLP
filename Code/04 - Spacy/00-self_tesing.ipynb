{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "# Process a text to create a Doc object\n",
    "doc = nlp(\"iPhone X is release on coming september third week!\")\n",
    "# doc.ents = [Span(doc, 0, 2, label=\"GADGET\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a span of tokens in the document\n",
    "span_of_tokens = doc[2:6]  # Represents tokens from index 2 to 5 (exclusive)\n",
    "span_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with the Span\n",
    "print(\"Text of the span:\", span_of_tokens.text)\n",
    "print(\"Tokens in the span:\", [token.text for token in span_of_tokens])\n",
    "print(\"Start index of the span:\", span_of_tokens.start)\n",
    "print(\"End index of the span:\", span_of_tokens.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Span\n",
    "new_span = Span(doc, start=0, end=2, label=\"CUSTOM_LABEL\")\n",
    "print(\"New span text:\", new_span.text)\n",
    "print(\"New span label:\", new_span.label_)\n",
    "print(type(new_span))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy.blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Create a blank English spaCy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process a text with the blank model\n",
    "doc = nlp(\"This is a blank spaCy model.\")\n",
    "\n",
    "# Access tokens in the document\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matcher Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Matcher is a powerful tool in spaCy for matching patterns in a text based on token attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a Matcher object using the vocabulary of the spaCy model\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define a pattern for matching the word \"example\"\n",
    "pattern = [{\"LOWER\": \"example\"}]\n",
    "\n",
    "# Add the pattern to the Matcher with a unique name (e.g., \"ExamplePattern\")\n",
    "matcher.add(\"ExamplePattern\", [pattern])\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"This is an example sentence. Another example is shown here.\")\n",
    "\n",
    "# Use the Matcher to find matches in the processed document\n",
    "matches = matcher(doc)\n",
    "print(f\"the patten matched: {matches}\")\n",
    "\n",
    "# Print the matches\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(f\"Match found: '{matched_span.text}' (start: {start}, end: {end})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: How to preorder the iPhone X\n",
      "spans: [iPhone X]\n",
      "doc.ents : (iPhone X,)\n",
      "doc: iPhone X is coming\n",
      "spans: [iPhone X]\n",
      "doc.ents : (iPhone X,)\n",
      "doc: Should I pay $1,000 for the iPhone X?\n",
      "spans: [iPhone X]\n",
      "doc.ents : (iPhone X,)\n",
      "doc: The iPhone 8 reviews are here\n",
      "spans: [iPhone 8]\n",
      "doc.ents : (iPhone 8,)\n",
      "doc: iPhone 11 vs iPhone 8: What's the difference?\n",
      "spans: [iPhone 11, iPhone 8]\n",
      "doc.ents : (iPhone 11, iPhone 8)\n",
      "doc: I need a new phone! Any tips?\n",
      "spans: []\n",
      "doc.ents : ()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "with open(\"data/iphone.json\", encoding=\"utf8\") as f:\n",
    "    text = json.loads(f.read())\n",
    "    # print(text)\n",
    "\n",
    "# Create a blank English spaCy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a Matcher object using the vocabulary of the spaCy model\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches \"iphone\" and a digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add patterns to the matcher and create docs with matched entities\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(text):\n",
    "    print(f\"doc: {doc}\")\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    print(f\"spans: {spans}\")\n",
    "    doc.ents = spans\n",
    "    print(f\"doc.ents : {doc.ents}\")\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[How to preorder the iPhone X,\n",
       " iPhone X is coming,\n",
       " Should I pay $1,000 for the iPhone X?,\n",
       " The iPhone 8 reviews are here,\n",
       " iPhone 11 vs iPhone 8: What's the difference?,\n",
       " I need a new phone! Any tips?]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Your Matcher definition (replace this with your actual pattern)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"example\"}]\n",
    "matcher.add(\"ExamplePattern\", [pattern])\n",
    "\n",
    "# List of texts to process\n",
    "# texts = [\"This is an example sentence.\", \"Another example is shown here.\"]\n",
    "with open(\"data/iphone.json\", encoding=\"utf8\") as f:\n",
    "    texts = json.loads(f.read())\n",
    "\n",
    "docs = []\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Create a list to store the entities\n",
    "    entities = []\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        # Create Span objects using the found matches\n",
    "        span = Span(doc, start, end, label=str(match_id))\n",
    "        entities.append(span)\n",
    "\n",
    "    # Assign the entities to the document's ents attribute\n",
    "    doc.ents = entities\n",
    "\n",
    "    # Append the modified document to the list\n",
    "    docs.append(doc)\n",
    "\n",
    "# Now, docs contains the processed documents with assigned entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy DocBin\n",
    "\n",
    "using spaCy's DocBin to convert a list of processed documents into a binary format suitable for training spaCy models. This binary format is useful for more efficient loading during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[How to preorder the iPhone X, iPhone X is coming, Should I pay $1,000 for the iPhone X?]\n",
      "[The iPhone 8 reviews are here, iPhone 11 vs iPhone 8: What's the difference?, I need a new phone! Any tips?]\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "# Assuming 'docs' is your list of processed documents\n",
    "\n",
    "# get the first half of the docs list and added to the train\n",
    "train_docs = docs[:len(docs) // 2]\n",
    "print(train_docs)\n",
    "# get the rest the docs list and added to the dev\n",
    "dev_docs = docs[len(docs) // 2:]\n",
    "print(dev_docs)\n",
    "\n",
    "# Create DocBin instances with an explicitly specified vocab\n",
    "train_doc_bin = DocBin(docs=train_docs)\n",
    "train_doc_bin.to_disk(\"docs/train.spacy\")\n",
    "\n",
    "dev_doc_bin = DocBin(docs=dev_docs)\n",
    "dev_doc_bin.to_disk(\"docs/dev.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
